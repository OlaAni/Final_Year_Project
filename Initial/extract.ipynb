{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('data\\Data\\musicFeatuers.csv')\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # df['label'] =  label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# df = df.drop(['filename'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# X = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var']]\n",
    "\n",
    "# y = df['label']\n",
    "\n",
    "# y = df[['label']]\n",
    "# X = df[df.columns.difference(['label'])]\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=1)\n",
    "# ## train a tree model\n",
    "# sk_dt.fit(X_train, y_train)\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# # model = LinearRegression()\n",
    "# # model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# predictions = sk_dt.predict(X_test)\n",
    "\n",
    "\n",
    "# print(classification_report(y_test, predictions))\n",
    "\n",
    "# y_pred = sk_dt.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# mse = mean_squared_error(Y_test,y_pred)\n",
    "# print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install librosa --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ## create the classifier object leaving all params to default values except random_state\n",
    "# sk_dt = DecisionTreeClassifier(random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues' 'classical' 'country' 'disco' 'hiphop' 'jazz' 'metal' 'pop'\n",
      " 'reggae' 'rock']\n",
      "6993 2997 6993 2997\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'..\\data\\Data\\features_3_sec.csv')\n",
    "\n",
    "# df = df.drop(['filename'], axis=1)\n",
    "\n",
    "# df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','label']]\n",
    "\n",
    "df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "df['label'] =  label_encoder.fit_transform(df['label'])\n",
    "\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "y = df[['label']]\n",
    "X = df[df.columns.difference(['label'])]\n",
    "\n",
    "\n",
    "## split both X and y using a ratio of 70% training - 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "target_name = ['blues', 'classical', 'country', 'disco', 'hiphop' ,'jazz' ,'metal', 'pop','reggae' ,'rock']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.75      0.82      0.78       302\n",
      "   classical       0.92      0.92      0.92       296\n",
      "     country       0.66      0.72      0.69       312\n",
      "       disco       0.76      0.76      0.76       283\n",
      "      hiphop       0.85      0.79      0.82       320\n",
      "        jazz       0.79      0.79      0.79       289\n",
      "       metal       0.88      0.90      0.89       303\n",
      "         pop       0.84      0.78      0.81       298\n",
      "      reggae       0.77      0.72      0.74       310\n",
      "        rock       0.62      0.62      0.62       284\n",
      "\n",
      "    accuracy                           0.78      2997\n",
      "   macro avg       0.78      0.78      0.78      2997\n",
      "weighted avg       0.78      0.78      0.78      2997\n",
      "\n",
      "Accuracy:  0.7814481147814482\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "## make predictions on the test portion (predict the labels of the rows from the test portion of X)\n",
    "predictionsXgb = xgb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictionsXgb, target_names=target_name))\n",
    "## can also output the confusion matrix\n",
    "# cm = confusion_matrix(y_test, predictions)\n",
    "# print(cm)\n",
    "\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictionsXgb))\n",
    "\n",
    "cols_when_model_builds = xgb.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.74      0.80      0.77       302\n",
      "   classical       0.92      0.93      0.93       296\n",
      "     country       0.67      0.73      0.70       312\n",
      "       disco       0.77      0.77      0.77       283\n",
      "      hiphop       0.85      0.80      0.83       320\n",
      "        jazz       0.77      0.81      0.79       289\n",
      "       metal       0.86      0.91      0.88       303\n",
      "         pop       0.85      0.77      0.81       298\n",
      "      reggae       0.77      0.73      0.75       310\n",
      "        rock       0.65      0.60      0.63       284\n",
      "\n",
      "    accuracy                           0.79      2997\n",
      "   macro avg       0.79      0.79      0.79      2997\n",
      "weighted avg       0.79      0.79      0.79      2997\n",
      "\n",
      "Accuracy:  0.7864531197864532\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb = xgboost.XGBClassifier(learning_rate=0.5, subsample=0.8, max_leaves=31, max_depth=6)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "## make predictions on the test portion (predict the labels of the rows from the test portion of X)\n",
    "predictionsXgb = xgb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictionsXgb, target_names=target_name))\n",
    "## can also output the confusion matrix\n",
    "# cm = confusion_matrix(y_test, predictions)\n",
    "# print(cm)\n",
    "\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictionsXgb))\n",
    "\n",
    "cols_when_model_builds = xgb.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.77      0.83      0.80       302\n",
      "   classical       0.91      0.92      0.92       296\n",
      "     country       0.68      0.76      0.72       312\n",
      "       disco       0.78      0.78      0.78       283\n",
      "      hiphop       0.85      0.79      0.82       320\n",
      "        jazz       0.80      0.81      0.80       289\n",
      "       metal       0.87      0.89      0.88       303\n",
      "         pop       0.84      0.77      0.80       298\n",
      "      reggae       0.78      0.73      0.75       310\n",
      "        rock       0.65      0.61      0.63       284\n",
      "\n",
      "    accuracy                           0.79      2997\n",
      "   macro avg       0.79      0.79      0.79      2997\n",
      "weighted avg       0.79      0.79      0.79      2997\n",
      "\n",
      "Accuracy:  0.7911244577911245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb = xgboost.XGBClassifier(n_estimators=1000,enable_catergorical=True,learning_rate=0.05)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "## make predictions on the test portion (predict the labels of the rows from the test portion of X)\n",
    "predictionsXgb = xgb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictionsXgb, target_names=target_name))\n",
    "## can also output the confusion matrix\n",
    "# cm = confusion_matrix(y_test, predictions)\n",
    "# print(cm)\n",
    "\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictionsXgb))\n",
    "\n",
    "cols_when_model_builds = xgb.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = xgb.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "predictionsForest = forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictionsForest, target_names=target_name))\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictionsForest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "predictionsDTC = dtc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictionsDTC, target_names=target_name))\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictionsDTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaledX = preprocessing.scale(X_train)\n",
    "scaledt = preprocessing.scale(X_test)\n",
    "\n",
    "\n",
    "KNC = KNeighborsClassifier(n_neighbors=1)\n",
    "KNC.fit(scaledX, y_train)\n",
    "predictionsKNC = KNC.predict(scaledt)\n",
    "\n",
    "print(classification_report(y_test, predictionsKNC, target_names=target_name))\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictionsKNC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def find_sim(data):\n",
    "    placeHoldername = 'test'\n",
    "    data['filename'] = placeHoldername\n",
    "\n",
    "    df_sim = pd.read_csv(r'..\\data\\Data\\features_30_sec.csv')\n",
    "\n",
    "    df_sim = df_sim[['filename','chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_sim['label'] = df_sim['label'].astype(\"string\")\n",
    "    df_sim['label'] =  label_encoder.fit_transform(df_sim['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    combined_df = pd.concat([df_sim, data], ignore_index=True)\n",
    "\n",
    "    combined_df = combined_df.set_index('filename')\n",
    "\n",
    " \n",
    "    labels = combined_df[['label']]\n",
    "\n",
    "    \n",
    "    scaled = preprocessing.scale(combined_df)\n",
    "    similarity = cosine_similarity(scaled)\n",
    "    sim_df_labels = pd.DataFrame(similarity)\n",
    "    sim_df_names = sim_df_labels.set_index(labels.index)\n",
    "    sim_df_names.columns = labels.index\n",
    "\n",
    "    series = sim_df_names[placeHoldername].sort_values(ascending=False)\n",
    "    series = series.drop(placeHoldername)\n",
    "\n",
    "\n",
    "    series = series.head(3).to_dict()\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    k = Counter(series)\n",
    "    \n",
    "    # Finding 3 highest values\n",
    "    series = k.most_common(3) \n",
    "    \n",
    "    for i in series:\n",
    "        print(i[0],\" :\",i[1],\" \")\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim(data):\n",
    "    placeHoldername = 'test'\n",
    "    data['filename'] = placeHoldername\n",
    "\n",
    "    df_sim = pd.read_csv(r'..\\data\\Data\\features_30_sec.csv')\n",
    "\n",
    "    df_sim = df_sim[['filename','chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_sim['label'] = df_sim['label'].astype(\"string\")\n",
    "    df_sim['label'] =  label_encoder.fit_transform(df_sim['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    combined_df = pd.concat([df_sim, data], ignore_index=True)\n",
    "\n",
    "    combined_df = combined_df.set_index('filename')\n",
    "\n",
    " \n",
    "    \n",
    "    similarity = cosine_similarity(combined_df)\n",
    "\n",
    "    sim_df_names = pd.DataFrame(similarity, columns=combined_df.index, index=combined_df.index)\n",
    "\n",
    "    series = sim_df_names[placeHoldername].sort_values(ascending=False)\n",
    "    series = series.drop(placeHoldername)\n",
    "\n",
    "    series = series.head(3).to_dict()\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    k = Counter(series)\n",
    "    \n",
    "    # Finding 3 highest values\n",
    "    series = k.most_common(3) \n",
    "    \n",
    "    for i in series:\n",
    "        print(i[0],\" :\",i[1],\" \")\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    chroma_sft_mean =  np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    chroma_sft_var =  librosa.feature.chroma_stft(y=y, sr=sr).var()\n",
    "\n",
    "    rms_mean = librosa.feature.rms(y=y).mean()\n",
    "    rms_var = librosa.feature.rms(y=y).var()\n",
    "\n",
    "    spectral_centroid_mean = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "    spectral_centroid_var = librosa.feature.spectral_centroid(y=y, sr=sr).var()\n",
    "\n",
    "    spectral_bandwith_mean = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "    spectral_bandwith_var = librosa.feature.spectral_bandwidth(y=y, sr=sr).var()\n",
    "\n",
    "    rolloff_mean = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "    rolloff_var = librosa.feature.spectral_rolloff(y=y, sr=sr).var()\n",
    "\n",
    "    zero_crossing_rate_mean = librosa.feature.zero_crossing_rate(y=y).mean()\n",
    "    zero_crossing_rate_var = librosa.feature.zero_crossing_rate(y=y).var()\n",
    "\n",
    "\n",
    "    harmony_mean = librosa.effects.harmonic(y).mean()\n",
    "    harmony_var = librosa.effects.harmonic(y).var()\n",
    "\n",
    "    tempo = librosa.feature.tempo(y=y, sr=sr)[0]\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"chroma_sft_mean: \",chroma_sft_mean)\n",
    "    print(\"chroma_sft_var: \",chroma_sft_var)\n",
    "    print(\"rms_mean: \",rms_mean)\n",
    "    print(\"rms_var: \",rms_var)\n",
    "    print(\"spectral_centroid_mean: \",spectral_centroid_mean)\n",
    "    print(\"spectral_centroid_var: \",spectral_centroid_var)\n",
    "    print(\"spectral_bandwith_mean: \",spectral_bandwith_mean)\n",
    "    print(\"spectral_bandwith_var: \",spectral_bandwith_var)\n",
    "    print(\"rolloff_mean: \",rolloff_mean)\n",
    "    print(\"rolloff_var: \",rolloff_var)\n",
    "    print(\"zero_crossing_rate_mean: \",zero_crossing_rate_mean)\n",
    "    print(\"zero_crossing_rate_var: \",zero_crossing_rate_var)\n",
    "    print(\"harmony_mean: \",harmony_mean)\n",
    "    print(\"harmony_var: \",harmony_var)\n",
    "    print(\"tempo: \",tempo)\n",
    "\n",
    "    features = pd.DataFrame({'chroma_stft_mean':[chroma_sft_mean],'chroma_stft_var':[chroma_sft_var],'rms_mean':[rms_mean],'rms_var':[rms_var],'spectral_centroid_mean':[spectral_centroid_mean],\n",
    "                             'spectral_centroid_var':[spectral_centroid_var],'spectral_bandwidth_mean':[spectral_bandwith_mean],'spectral_bandwidth_var':[spectral_bandwith_var],\n",
    "                             'rolloff_mean':[rolloff_mean],'rolloff_var':[rolloff_var],'zero_crossing_rate_mean':[zero_crossing_rate_mean],'zero_crossing_rate_var':[zero_crossing_rate_var],\n",
    "                             'harmony_mean':[harmony_mean],'harmony_var':[harmony_var],'tempo':[tempo],})\n",
    "    \n",
    "\n",
    "    features = features.reindex(columns=cols_when_model_builds)\n",
    "\n",
    "    # features = features.reshape(-1,1)\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "    y, sr = librosa.load(file,  duration=3)\n",
    "\n",
    "    chroma_sft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    harmony = librosa.effects.harmonic(y)\n",
    "    tempo = librosa.feature.tempo(y=y, sr=sr)[0]\n",
    "\n",
    "    features = pd.DataFrame({'chroma_stft_mean':[chroma_sft.mean()],'chroma_stft_var':[chroma_sft.var()],'rms_mean':[rms.mean()],'rms_var':[rms.var()],'spectral_centroid_mean':[spectral_centroid.mean()],\n",
    "                             'spectral_centroid_var':[spectral_centroid.var()],'spectral_bandwidth_mean':[spectral_bandwidth.mean()],'spectral_bandwidth_var':[spectral_bandwidth.var()],\n",
    "                             'rolloff_mean':[rolloff.mean()],'rolloff_var':[rolloff.var()],'zero_crossing_rate_mean':[zero_crossing_rate.mean()],'zero_crossing_rate_var':[zero_crossing_rate.var()],\n",
    "                             'harmony_mean':[harmony.mean()],'harmony_var':[harmony.var()],'tempo':[tempo],})\n",
    "    \n",
    "\n",
    "    features = features.reindex(columns=cols_when_model_builds)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reggae.00071.wav  : 0.88537640896689  \n",
      "pop.00084.wav  : 0.862889703797779  \n",
      "reggae.00050.wav  : 0.8555991520683579  \n",
      "Similiar Songs: [('reggae.00071.wav', 0.88537640896689), ('pop.00084.wav', 0.862889703797779), ('reggae.00050.wav', 0.8555991520683579)]\n"
     ]
    }
   ],
   "source": [
    "features1 =  extract_features(r\"..\\music\\big.mp3\")\n",
    "\n",
    "genre1 = xgb.predict(features1)\n",
    "\n",
    "features1['label'] = genre1[0]\n",
    "\n",
    "print(\"Similiar Songs:\",find_sim(features1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load('model.pkl')\n",
    "genre1 = model.predict(features1)\n",
    "\n",
    "print(genre1[0])\n",
    "print(model.get_booster().feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pred(result):\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    if(result is None):\n",
    "        return \"Null\"\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame.from_dict(result, orient='index')\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    newData=[]\n",
    "    for i in range(len(df)):\n",
    "        y = json.loads(combined_df[0][i])\n",
    "        newData.append(y)\n",
    "\n",
    "    if(len(newData)<3):\n",
    "        return \"Not enough\"\n",
    "\n",
    "    newData = pd.DataFrame(newData)\n",
    "\n",
    "    finalDf = pd.DataFrame()\n",
    "    for i in range(len(newData)):\n",
    "        df = pd.DataFrame([newData[0][i]])\n",
    "        finalDf = pd.concat([finalDf, df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    # finalDf =  finalDf.drop(['label'], axis=1)\n",
    "\n",
    "    features = pd.DataFrame(columns=finalDf.columns)\n",
    "\n",
    "    for column in finalDf:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(finalDf, finalDf[column], test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        features.loc[0, column] = prediction[0]  # Assuming you want to update the first row (index 0)\n",
    "        # print(column,\":\",prediction[0])\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firebase import firebase\n",
    "\n",
    "firebase = firebase.FirebaseApplication('https://orpheus-3a4fa-default-rtdb.europe-west1.firebasedatabase.app/', None)\n",
    "result = firebase.get('/users', 'LPzlgxH7J6TlEkBU39oXYMMGSlU2')\n",
    "\n",
    "pred= find_pred(result)\n",
    "print(pred)\n",
    "# find_sim(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pred_poly(data, features, predicted_feature):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    features = features.drop(['filename'], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, data[predicted_feature], test_size=0.2)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    prediction = model.predict(features)\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(file):\n",
    "#     y, sr = librosa.load(file)\n",
    "\n",
    "#     chroma_sft_mean =  np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "#     chroma_sft_var =  librosa.feature.chroma_stft(y=y, sr=sr).var()\n",
    "\n",
    "#     rms_mean = librosa.feature.rms(y=y).mean()\n",
    "#     rms_var = librosa.feature.rms(y=y).var()\n",
    "\n",
    "#     spectral_centroid_mean = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "#     spectral_centroid_var = librosa.feature.spectral_centroid(y=y, sr=sr).var()\n",
    "\n",
    "#     spectral_bandwith_mean = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "#     spectral_bandwith_var = librosa.feature.spectral_bandwidth(y=y, sr=sr).var()\n",
    "\n",
    "#     rolloff_mean = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "#     rolloff_var = librosa.feature.spectral_rolloff(y=y, sr=sr).var()\n",
    "\n",
    "#     zero_crossing_rate_mean = librosa.feature.zero_crossing_rate(y=y).mean()\n",
    "#     zero_crossing_rate_var = librosa.feature.zero_crossing_rate(y=y).var()\n",
    "\n",
    "\n",
    "#     harmony_mean = librosa.effects.harmonic(y).mean()\n",
    "#     harmony_var = librosa.effects.harmonic(y).var()\n",
    "\n",
    "#     tempo = librosa.feature.tempo(y=y, sr=sr)[0]\n",
    "\n",
    "    \n",
    "\n",
    "#     # print(\"chroma_sft_mean: \",chroma_sft_mean)\n",
    "#     # print(\"chroma_sft_var: \",chroma_sft_var)\n",
    "#     # print(\"rms_mean: \",rms_mean)\n",
    "#     # print(\"rms_var: \",rms_var)\n",
    "#     # print(\"spectral_centroid_mean: \",spectral_centroid_mean)\n",
    "#     # print(\"spectral_centroid_var: \",spectral_centroid_var)\n",
    "#     # print(\"spectral_bandwith_mean: \",spectral_bandwith_mean)\n",
    "#     # print(\"spectral_bandwith_var: \",spectral_bandwith_var)\n",
    "#     # print(\"rolloff_mean: \",rolloff_mean)\n",
    "#     # print(\"rolloff_var: \",rolloff_var)\n",
    "#     # print(\"zero_crossing_rate_mean: \",zero_crossing_rate_mean)\n",
    "#     # print(\"zero_crossing_rate_var: \",zero_crossing_rate_var)\n",
    "#     # print(\"harmony_mean: \",harmony_mean)\n",
    "#     # print(\"harmony_var: \",harmony_var)\n",
    "#     # print(\"tempo: \",tempo)\n",
    "#     print('---------------------------------------------------')\n",
    "\n",
    "#     features = pd.DataFrame({'chroma_stft_mean':[chroma_sft_mean],'chroma_stft_var':[chroma_sft_var],'rms_mean':[rms_mean],'rms_var':[rms_var],'spectral_centroid_mean':[spectral_centroid_mean],\n",
    "#                              'spectral_centroid_var':[spectral_centroid_var],'spectral_bandwidth_mean':[spectral_bandwith_mean],'spectral_bandwidth_var':[spectral_bandwith_var],\n",
    "#                              'rolloff_mean':[rolloff_mean],'rolloff_var':[rolloff_var],'zero_crossing_rate_mean':[zero_crossing_rate_mean],'zero_crossing_rate_var':[zero_crossing_rate_var],\n",
    "#                              'harmony_mean':[harmony_mean],'harmony_var':[harmony_var],'tempo':[tempo],})\n",
    "    \n",
    "\n",
    "#     features = features.reindex(columns=cols_when_model_builds)\n",
    "\n",
    "#     # features = features.reshape(-1,1)\n",
    "#     return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "    y, sr = librosa.load(file, duration=3)\n",
    "\n",
    "    chroma_sft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    harmony = librosa.effects.harmonic(y)\n",
    "    tempo = librosa.feature.tempo(y=y, sr=sr)[0]\n",
    "\n",
    "    features = pd.DataFrame({'chroma_stft_mean':[chroma_sft.mean()],'chroma_stft_var':[chroma_sft.var()],'rms_mean':[rms.mean()],'rms_var':[rms.var()],'spectral_centroid_mean':[spectral_centroid.mean()],\n",
    "                             'spectral_centroid_var':[spectral_centroid.var()],'spectral_bandwidth_mean':[spectral_bandwidth.mean()],'spectral_bandwidth_var':[spectral_bandwidth.var()],\n",
    "                             'rolloff_mean':[rolloff.mean()],'rolloff_var':[rolloff.var()],'zero_crossing_rate_mean':[zero_crossing_rate.mean()],'zero_crossing_rate_var':[zero_crossing_rate.var()],\n",
    "                             'harmony_mean':[harmony.mean()],'harmony_var':[harmony.var()],'tempo':[tempo],})\n",
    "    \n",
    "\n",
    "    features = features.reindex(columns=cols_when_model_builds)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_score(proba):\n",
    "    from collections import Counter\n",
    "    confi = {}\n",
    "    i=0\n",
    "    for val in proba[0]:\n",
    "        rounded = round(val *100,2)\n",
    "        # print(rounded ,\"% :\",target_name[i])\n",
    "        confi[target_name[i]] = rounded\n",
    "        i = i+1\n",
    "\n",
    "    k = Counter(confi)\n",
    "    \n",
    "    # Finding 3 highest values\n",
    "    high = k.most_common(3) \n",
    "    \n",
    "    for i in high:\n",
    "        print(i[0],\" :\",i[1],\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'blues':0, 'classical':1, 'country':2, 'disco':3, 'hiphop':4 ,'jazz':5 ,'metal':6, 'pop':7,'reggae':8 ,'rock':9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    from pytube import YouTube\n",
    "    from googleapiclient.discovery import build\n",
    "\n",
    "    api_key = 'AIzaSyCghPkifWFcLs_iN5CCvLIlQwvWBXxIxxY'\n",
    "\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    search_response = youtube.search().list(q=query,type='video',part='id,snippet',maxResults=1).execute()\n",
    "\n",
    "\n",
    "\n",
    "    for search_result in search_response.get('items', []):\n",
    "        video_id = search_result['id']['videoId']\n",
    "        # video_title = search_result['snippet']['title']\n",
    "        video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "\n",
    "        #print(f'Video Ulr: {video_url}')\n",
    "        url = video_url\n",
    "\n",
    "    video = YouTube(url)\n",
    "\n",
    "    video_duration_seconds = video.length\n",
    "    video_duration_minutes = video_duration_seconds / 60\n",
    "\n",
    "    if video_duration_minutes < 6:\n",
    "        stream = video.streams.filter(only_audio=True).first()\n",
    "        stream.download(filename=f\"musicaudio.mp3\")\n",
    "        sound = AudioSegment.from_file(r\"musicaudio.mp3\")\n",
    "        start_time = 0  \n",
    "        end_time = 30 * 1000\n",
    "\n",
    "        audio_segment = sound[start_time:end_time]\n",
    "\n",
    "        \n",
    "        # audio_segment.export(r\"../music/downloaded/musicaudio.mp3\", format=\"mp3\")\n",
    "        return extract_features(audio_segment)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid file: <pydub.audio_segment.AudioSegment object at 0x0000020B1CA4E9D0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast christmas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 37\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     33\u001b[0m     audio_segment \u001b[38;5;241m=\u001b[39m sound[start_time:end_time]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# audio_segment.export(r\"../music/downloaded/musicaudio.mp3\", format=\"mp3\")\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(file):\n\u001b[1;32m----> 2\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     chroma_sft \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mchroma_stft(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[0;32m      5\u001b[0m     rms \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mrms(y\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    205\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    211\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\soundfile.py:1212\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_virtual(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_virtual_io(file),\n\u001b[0;32m   1210\u001b[0m                                     mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, _ffi\u001b[38;5;241m.\u001b[39mNULL)\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid file: <pydub.audio_segment.AudioSegment object at 0x0000020B1CA4E9D0>"
     ]
    }
   ],
   "source": [
    "search(\"last christmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 =  extract_features(r\"..\\music\\Outkast-Hey Ya!.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 =  extract_features(r\"..\\music\\Beyoncé-Single Ladies.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal  : 35.47  \n",
      "country  : 21.75  \n",
      "blues  : 20.07  \n",
      "metal\n",
      "   chroma_stft_mean  chroma_stft_var  harmony_mean  harmony_var  rms_mean  \\\n",
      "0          0.427931         0.081674     -0.000044     0.013661  0.181682   \n",
      "\n",
      "   rms_var  rolloff_mean    rolloff_var  spectral_bandwidth_mean  \\\n",
      "0  0.00147   4199.140249  722541.787083              2222.723698   \n",
      "\n",
      "   spectral_bandwidth_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0            65922.914993             2104.610358          159325.746021   \n",
      "\n",
      "        tempo  zero_crossing_rate_mean  zero_crossing_rate_var  \n",
      "0  161.499023                 0.093363                0.000817  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "genre2 = xgb.predict(features2)\n",
    "genreP2 = xgb.predict_proba(features2)\n",
    "\n",
    "label2 = label_encoder.inverse_transform(genre2)[0]\n",
    "confidence_score(genreP2)\n",
    "print(label2)\n",
    "print(features2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer(norm='l1') \n",
    "normalized_data = scaler.fit_transform(features2)\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=features2.columns)\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix_features2 = xgboost.DMatrix(features2)\n",
    "xgtest = xgboost.DMatrix(features2)\n",
    "contributions = xgb.get_booster().predict(xgtest, pred_contribs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contributions = np.sum(contributions, axis=1)\n",
    "\n",
    "feature_names = features2.columns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_names, all_contributions)\n",
    "plt.title('Contributions for All Features')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Summed Contribution')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = xgb.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 =  extract_features(r\"..\\music\\Beyoncé-Single Ladies.mp3\")\n",
    "features2 =  extract_features(r\"..\\music\\Outkast-Hey Ya!.mp3\")\n",
    "features3=  extract_features(r\"../music/Taylor Swift-Bad Blood.mp3\")\n",
    "\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "genre1 = xgb.predict(features1)\n",
    "genreP1 = xgb.predict_proba(features1)\n",
    "genre2 = xgb.predict(features2)\n",
    "genreP2 = xgb.predict_proba(features2)\n",
    "\n",
    "genre3 = xgb.predict(features3)\n",
    "genreP3 = xgb.predict_proba(features3)\n",
    "\n",
    "features1['label'] = genre1[0]\n",
    "features2['label'] = genre2[0]\n",
    "features3['label'] = genre3[0]\n",
    "\n",
    "label1 = label_encoder.inverse_transform(genre1)[0]\n",
    "label2 = label_encoder.inverse_transform(genre2)[0]\n",
    "label3 = label_encoder.inverse_transform(genre3)[0]\n",
    "\n",
    "confidence_score(genreP1)\n",
    "print(label1)\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "confidence_score(genreP2)\n",
    "print(label2)\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "confidence_score(genreP3)\n",
    "print(label3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Similiar Songs:\",find_sim(features1))\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "new_features = features1\n",
    "new_features['tempo'] = 400\n",
    "print(find_sim(new_features))\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([features1, features2], ignore_index=True)\n",
    "combined_df = pd.concat([combined_df, features3], ignore_index=True)\n",
    "combined_df = combined_df.drop(['filename'], axis=1)\n",
    "\n",
    "feature = 'tempo'\n",
    "pred = find_pred(combined_df, features1)\n",
    "print(\"Predicted feature: \",pred)\n",
    "# pred_features = features1\n",
    "# pred_features[feature] = pred\n",
    "print(\"Predicted Song: \" ,find_sim(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spacy\n",
    "# %pip install ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message: \n\u001b[0;32m      8\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend( \n\u001b[0;32m      9\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message}, \n\u001b[0;32m     10\u001b[0m     ) \n\u001b[1;32m---> 11\u001b[0m     chat \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     14\u001b[0m reply \u001b[38;5;241m=\u001b[39m chat\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGPT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreply\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"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\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "while True: \n",
    "    message = input(\"User : \") \n",
    "    if message: \n",
    "        message.append( \n",
    "            {\"role\": \"user\", \"content\": message}, \n",
    "        ) \n",
    "        chat = openai.ChatCompletion.create( \n",
    "            model=\"gpt-3.5-turbo\", messages=messages \n",
    "        ) \n",
    "    reply = chat.choices[0].message.content \n",
    "    print(f\"ChatGPT: {reply}\") \n",
    "    message.append({\"role\": \"assistant\", \"content\": reply}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nbimporter\n",
    "# %pip install pytube\n",
    "# %pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgbo\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import youtube_dl\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'..\\data\\Data\\features_3_sec.csv')\n",
    "\n",
    "# # df = df.drop(['filename'], axis=1)\n",
    "\n",
    "# # df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','label']]\n",
    "\n",
    "# df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# df['label'] =  label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# print(label_encoder.classes_)\n",
    "\n",
    "# y = df[['label']]\n",
    "# X = df[df.columns.difference(['label'])]\n",
    "\n",
    "\n",
    "# ## split both X and y using a ratio of 70% training - 30% testing\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "# xgb = xgboost.XGBClassifier(n_estimators=1000,enable_catergorical=True,learning_rate=0.05)\n",
    "# xgb.fit(X_train, y_train)\n",
    "\n",
    "## make predictions on the test portion (predict the labels of the rows from the test portion of X)\n",
    "# predictions = xgb.predict(X_test)\n",
    "\n",
    "# target_name = ['blues', 'classical', 'country', 'disco', 'hiphop' ,'jazz' ,'metal', 'pop','reggae' ,'rock']\n",
    "\n",
    "\n",
    "# print(classification_report(y_test, predictions, target_names=target_name))\n",
    "# ## can also output the confusion matrix\n",
    "# # cm = confusion_matrix(y_test, predictions)\n",
    "# # print(cm)\n",
    "\n",
    "# print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "# cols_when_model_builds = xgb.feature_names_in_\n",
    "\n",
    "\n",
    "# xgb = xgbo.Booster(model_file=r'model.pkl')\n",
    "# cols_when_model_builds = xgb.num_features\n",
    "# print(cols_when_model_builds)\n",
    "\n",
    "\n",
    "df = pd.read_csv(r'music_data/features_3_sec.csv')\n",
    "df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] =  label_encoder.fit_transform(df['label'])\n",
    "\n",
    "\n",
    "target_name = ['blues', 'classical', 'country', 'disco', 'hiphop' ,'jazz' ,'metal', 'pop','reggae' ,'rock']\n",
    "\n",
    "\n",
    "\n",
    "xgb = joblib.load('model.pkl')\n",
    "cols_when_model_builds = xgb.get_booster().feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def find_sim(data):\n",
    "    placeHoldername = 'test'\n",
    "    data['filename'] = placeHoldername\n",
    "\n",
    "    df_sim = pd.read_csv(r'..\\data\\Data\\features_30_sec.csv')\n",
    "\n",
    "    df_sim = df_sim[['filename','chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_sim['label'] = df_sim['label'].astype(\"string\")\n",
    "    df_sim['label'] =  label_encoder.fit_transform(df_sim['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    combined_df = pd.concat([df_sim, data], ignore_index=True)\n",
    "\n",
    "    combined_df = combined_df.set_index('filename')\n",
    "\n",
    " \n",
    "    labels = combined_df[['label']]\n",
    "\n",
    "    \n",
    "    scaled = preprocessing.scale(combined_df)\n",
    "    similarity = cosine_similarity(scaled)\n",
    "    sim_df_labels = pd.DataFrame(similarity)\n",
    "    sim_df_names = sim_df_labels.set_index(labels.index)\n",
    "    sim_df_names.columns = labels.index\n",
    "\n",
    "    series = sim_df_names[placeHoldername].sort_values(ascending=False)\n",
    "    series = series.drop(placeHoldername)\n",
    "    return series.head(3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pred(data, features, predicted_feature):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    features = features.drop(['filename'], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, data[predicted_feature], test_size=0.2)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    prediction = model.predict(features)\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_score(proba):\n",
    "    from collections import Counter\n",
    "    confi = {}\n",
    "    i=0\n",
    "    for val in proba[0]:\n",
    "        rounded = round(val *100,2)\n",
    "        confi[target_name[i]] = rounded\n",
    "        i = i+1\n",
    "\n",
    "    k = Counter(confi)\n",
    "    \n",
    "    high = k.most_common(3) \n",
    "    \n",
    "    # for i in high:\n",
    "    #     print(i[0],\" :\",i[1],\" \")\n",
    "\n",
    "    return high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    chroma_sft_mean =  np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    chroma_sft_var =  librosa.feature.chroma_stft(y=y, sr=sr).var()\n",
    "\n",
    "    rms_mean = librosa.feature.rms(y=y).mean()\n",
    "    rms_var = librosa.feature.rms(y=y).var()\n",
    "\n",
    "    spectral_centroid_mean = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "    spectral_centroid_var = librosa.feature.spectral_centroid(y=y, sr=sr).var()\n",
    "\n",
    "    spectral_bandwith_mean = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "    spectral_bandwith_var = librosa.feature.spectral_bandwidth(y=y, sr=sr).var()\n",
    "\n",
    "    rolloff_mean = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "    rolloff_var = librosa.feature.spectral_rolloff(y=y, sr=sr).var()\n",
    "\n",
    "    zero_crossing_rate_mean = librosa.feature.zero_crossing_rate(y=y).mean()\n",
    "    zero_crossing_rate_var = librosa.feature.zero_crossing_rate(y=y).var()\n",
    "\n",
    "\n",
    "    harmony_mean = librosa.effects.harmonic(y).mean()\n",
    "    harmony_var = librosa.effects.harmonic(y).var()\n",
    "\n",
    "    tempo = librosa.feature.tempo(y=y, sr=sr)[0]\n",
    "\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"chroma_sft_mean: \",chroma_sft_mean)\n",
    "    # print(\"chroma_sft_var: \",chroma_sft_var)\n",
    "    print(\"rms_mean: \",rms_mean)\n",
    "    # print(\"rms_var: \",rms_var)\n",
    "    print(\"spectral_centroid_mean: \",spectral_centroid_mean)\n",
    "    # print(\"spectral_centroid_var: \",spectral_centroid_var)\n",
    "    print(\"spectral_bandwith_mean: \",spectral_bandwith_mean)\n",
    "    # print(\"spectral_bandwith_var: \",spectral_bandwith_var)\n",
    "    print(\"rolloff_mean: \",rolloff_mean)\n",
    "    # print(\"rolloff_var: \",rolloff_var)\n",
    "    print(\"zero_crossing_rate_mean: \",zero_crossing_rate_mean)\n",
    "    # print(\"zero_crossing_rate_var: \",zero_crossing_rate_var)\n",
    "    print(\"harmony_mean: \",harmony_mean)\n",
    "    # print(\"harmony_var: \",harmony_var)\n",
    "    print(\"tempo: \",tempo)\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "    features = pd.DataFrame({'chroma_stft_mean':[chroma_sft_mean],'chroma_stft_var':[chroma_sft_var],'rms_mean':[rms_mean],'rms_var':[rms_var],'spectral_centroid_mean':[spectral_centroid_mean],\n",
    "                             'spectral_centroid_var':[spectral_centroid_var],'spectral_bandwidth_mean':[spectral_bandwith_mean],'spectral_bandwidth_var':[spectral_bandwith_var],\n",
    "                             'rolloff_mean':[rolloff_mean],'rolloff_var':[rolloff_var],'zero_crossing_rate_mean':[zero_crossing_rate_mean],'zero_crossing_rate_var':[zero_crossing_rate_var],\n",
    "                             'harmony_mean':[harmony_mean],'harmony_var':[harmony_var],'tempo':[tempo],})\n",
    "    \n",
    "\n",
    "    features = features.reindex(columns=cols_when_model_builds)\n",
    "\n",
    "    # features = features.reshape(-1,1)\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    from pytube import YouTube\n",
    "    from googleapiclient.discovery import build\n",
    "\n",
    "    api_key = 'AIzaSyCghPkifWFcLs_iN5CCvLIlQwvWBXxIxxY'\n",
    "\n",
    "    # Initialize the YouTube Data API\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Perform a video search\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        type='video',\n",
    "        part='id,snippet',\n",
    "        maxResults=1 \n",
    "    ).execute()\n",
    "\n",
    "    # Iterate through the search results and get video information\n",
    "    for search_result in search_response.get('items', []):\n",
    "        video_id = search_result['id']['videoId']\n",
    "        # video_title = search_result['snippet']['title']\n",
    "        video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "\n",
    "        print(f'Video Ulr: {video_url}')\n",
    "        url = video_url\n",
    "\n",
    "    video = YouTube(url)\n",
    "\n",
    "    stream = video.streams.filter(only_audio=True).first()\n",
    "    stream.download(filename=f\"musicaudio.mp3\")\n",
    "    \n",
    "    sound = AudioSegment.from_file(r\"../AI/musicaudio.mp3\")\n",
    "    start_time = 0  \n",
    "    end_time = 30 * 1000\n",
    "\n",
    "    audio_segment = sound[start_time:end_time]\n",
    "\n",
    "    audio_segment.export(\"../music/downloaded/musicaudio.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot(Orpheus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "patterns = [\n",
    "    [{\"LOWER\": \"hello\"}],\n",
    "    [{\"LOWER\": \"hi\"}],\n",
    "    [{\"LOWER\": \"how\"}, {\"LOWER\": \"are\"}, {\"LOWER\": \"you\"}],\n",
    "    [{\"LOWER\": \"find\"}, {\"LOWER\": \"this\"}, {\"LOWER\": \"song\"}, {\"LOWER\": \"but\"}, {\"LOWER\": {\"REGEX\": \".*\"}}],\n",
    "    [{\"LOWER\": \"find\"}, {\"LOWER\": \"similiar\"}, {\"LOWER\": \"songs\"}],\n",
    "\n",
    "]\n",
    "\n",
    "responses = {\n",
    "    \"greetings\": [\n",
    "        [{\"LOWER\": \"hello\"}],\n",
    "        [{\"LOWER\": \"hi\"}],\n",
    "    ],\n",
    "    \"inquiries\": [\n",
    "        [{\"LOWER\": \"how\"}, {\"LOWER\": \"are\"}, {\"LOWER\": \"you\"}],\n",
    "    ],\n",
    "\n",
    "    \"find_increased\": [\n",
    "        [{\"LOWER\": \"find\"}],\n",
    "    ],\n",
    "\n",
    "    \"find_sim\": [\n",
    "        [{\"LOWER\": \"search\"},{\"LOWER\": \"for\"},{\"LOWER\": \"similiar\"},{\"LOWER\": \"songs\"}],\n",
    "        [{\"LOWER\": \"search\"},{\"LOWER\": \"for\"},{\"LOWER\": \"songs\"},{\"LOWER\": \"like\"},{\"LOWER\": \"this\"}],\n",
    "    ],\n",
    "\n",
    "    \"like\": [\n",
    "        [{\"LOWER\": \"i\"}, {\"LOWER\": \"like\"},  {\"LOWER\": {\"REGEX\": \".*\"}}],\n",
    "        [{\"LOWER\": \"i\"}, {\"LOWER\": \"love\"},  {\"LOWER\": {\"REGEX\": \".*\"}}],\n",
    "        [{\"LOWER\": \"i\"}, {\"LOWER\": \"want\"},  {\"LOWER\": {\"REGEX\": \".*\"}}],\n",
    "        [{\"LOWER\": \"i\"}, {\"LOWER\": \"need\"},  {\"LOWER\": {\"REGEX\": \".*\"}}],\n",
    "    ],\n",
    "\n",
    "    \"general\": [\n",
    "        [{\"LOWER\": \"new\"}],\n",
    "        [{\"LOWER\": \"bored\"}],\n",
    "        [{\"LOWER\": \"what\"}],[{\"LOWER\": \"is\"}],[{\"LOWER\": \"your\"}],[{\"LOWER\": \"name\"}],\n",
    "    ],    \n",
    "}\n",
    "\n",
    "\n",
    "fast_words = [\"faster\",\"quicker\"]\n",
    "slow_words = [\"slower\",\"calmer\"]\n",
    "loud_words = [\"louder\",\"screamer\"]\n",
    "quiet_words = [\"softer\",\"quieter\"]\n",
    "higher_pitch_words = [] # chroma\n",
    "lower_pitch_words = []\n",
    "happy_words = [] #sprectral\n",
    "sad_words = []\n",
    "sporadic_words = []#bandwith\n",
    "beats_words  = []#zero_crossing rate\n",
    "unbeats_words = []\n",
    "harmony = []#ambient sounds\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "for category, patterns in responses.items():\n",
    "    for pattern in patterns:\n",
    "        matcher.add(category, [pattern])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general(user_input):\n",
    "    ##fill with general conversation about \n",
    "    ##history of prevois questions\n",
    "    newString = \"Hello\"\n",
    "    if user_input.find(\"name\")!=-1:\n",
    "        newString = \"My name is DJ ORPHEUS, no need tell me yours\"\n",
    "    elif user_input.find(\"bored\")!=-1:\n",
    "        newString = \"Thats actually crazy\"\n",
    "\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_spotify(genres, tempo):\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "    client_id = 'b0715167b5814e2c92afb73034ed1416'\n",
    "    client_secret = 'f25f4de9272c49948019dc270b2413d8'\n",
    "\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "\n",
    "\n",
    "    seed_genres = [genres[0]]\n",
    "    target_tempo = int(tempo)\n",
    "    min = target_tempo * 0.9\n",
    "    max = target_tempo * 1.1\n",
    "\n",
    "\n",
    "    recommendations = sp.recommendations(seed_genres=seed_genres,  target_tempo=(min, max))\n",
    "\n",
    "    if recommendations['tracks']:\n",
    "        first_track = recommendations['tracks'][0]\n",
    "        track_name = first_track['name']\n",
    "        artist_name = first_track['artists'][0]['name']\n",
    "\n",
    "        return f'Song: {track_name} by {artist_name}'\n",
    "    else:\n",
    "        return 'No recommendations found from spotify.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input, amoSim, features1=None):\n",
    "    doc = nlp(user_input)\n",
    "    matches = matcher(doc)\n",
    "    if matches:\n",
    "        match_id, start,end = matches[0]\n",
    "        category = nlp.vocab.strings[match_id]\n",
    "        if category == \"greetings\":\n",
    "           return \"Orpheus: Hello! How can I assist you?\"\n",
    "        elif category == \"inquiries\":\n",
    "           return \"Orpheus: I'm just the world's best DJ. How can I assist you?\"\n",
    "        elif category == \"like\":\n",
    "            print(\"Loading....\")  \n",
    "            # extracted_word = doc[1].text\n",
    "            before, keyword,extracted_word = doc.text.partition(doc[1].text)\n",
    "            search(extracted_word)\n",
    "            features1 = extract_features(r\"../music/downloaded/musicaudio.mp3\")\n",
    "            genre1 = xgb.predict(features1)\n",
    "            genreProb = xgb.predict_proba(features1)\n",
    "            features1['label'] = genre1[0]\n",
    "            label = label_encoder.inverse_transform(features1['label'])[0]\n",
    "            high = confidence_score(genreProb)\n",
    "            print(\"Confidence Scores of song Genre\")\n",
    "            for i in high:\n",
    "                print(i[0],\" :\",i[1],\"%\")\n",
    "            return \"Orpheus: You \", keyword , extracted_word,\" They seem to make \" ,label,\" Im saying with\", high[0][1],\"% confidence\"  \n",
    "        elif category == \"find_increased\":\n",
    "            if features1 is None:\n",
    "                return \"Orpheus: Exctract a song to use this great feature\"\n",
    "            else:\n",
    "                words = [token.text for token in doc if token.is_alpha]\n",
    "                valid = False\n",
    "                for s in words:\n",
    "                    if(s in fast_words):\n",
    "                        features = 'tempo'\n",
    "                        value = features1[features]\n",
    "                        value = value/100\n",
    "                        valid=True\n",
    "                    elif(s in slow_words):\n",
    "                        features = 'tempo'\n",
    "                        value = features1[features]\n",
    "                        value = -value/100\n",
    "                        valid=True\n",
    "                    elif(s in loud_words):\n",
    "                        features = 'rms_mean'\n",
    "                        value = 50\n",
    "                        valid=True\n",
    "                    elif(s in quiet_words):\n",
    "                        features = 'rms_mean'\n",
    "                        value = -50\n",
    "                        valid=True\n",
    "                if(valid):\n",
    "                    new_features = features1\n",
    "                    new_features[features]+= value\n",
    "                    print(value)\n",
    "                    return find_sim(new_features)\n",
    "                else:\n",
    "                    return \"Orpheus: I'm sorry, but im going to need a valid song feature\"\n",
    "                \n",
    "        elif category == \"find_sim\":      \n",
    "            if features1 is None:\n",
    "                return \"Orpheus: Exctract a song to use this great feature\"\n",
    "            else:\n",
    "                if amoSim>=3:\n",
    "                    amoSim=0\n",
    "                    return \"Orpheus: I just put on some back to back bangers!!!\"\n",
    "                else:\n",
    "                    amoSim = amoSim+1\n",
    "                    sim = find_sim(features1)\n",
    "                    for key, value in sim.items():\n",
    "                        print(key,\" :\",round(value,2),\"% similiar\")\n",
    "                    label = label_encoder.inverse_transform(features1['label'])[0]\n",
    "                    print(\"Recommendation from Spotify: \",search_spotify(label,features1['tempo']))\n",
    "                    return \"Similiar Songs\"\n",
    "            \n",
    "        elif category==\"general\":\n",
    "            extracted_word = doc.text\n",
    "            return \"Orpheus:\", general(extracted_word)\n",
    "    else:\n",
    "        return \"Orpheus: I'm sorry, I don't understand that.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* add extract feature depending on download location\n",
    "* add more word features in the dictionary\n",
    "* clean prints\n",
    "* change find_increased features\n",
    "* search features change\n",
    "* spotify api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(name):\n",
    "    print(\"Loading....\")  \n",
    "    features1 = extract_features(name)\n",
    "    print(\"Extracted\")\n",
    "    genre1 = xgb.predict(features1)\n",
    "    genreProb = xgb.predict_proba(features1)\n",
    "    features1['label'] = genre1[0]\n",
    "    label = label_encoder.inverse_transform(features1['label'])[0]\n",
    "    high = confidence_score(genreProb)\n",
    "    print(\"Orpheus: This song is sounding a lot like the\", label,\" genre. Im saying with\", high[0][1],\"% confidence\")\n",
    "    print(\"Confidence Scores\")\n",
    "    for i in high:\n",
    "        print(i[0],\" :\",i[1],\"%\")\n",
    "    return features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orpheus: Hello My Name is DJ ORPHEUS, need some songs im here to help\n",
      "Loading....\n",
      "----------------------------------------------------------------------------\n",
      "chroma_sft_mean:  0.3339875\n",
      "rms_mean:  0.14723456\n",
      "spectral_centroid_mean:  1826.6113424789125\n",
      "spectral_bandwith_mean:  2075.3115709653976\n",
      "rolloff_mean:  3630.653045937742\n",
      "zero_crossing_rate_mean:  0.07000411184210527\n",
      "harmony_mean:  1.8988116e-05\n",
      "tempo:  151.99908088235293\n",
      "----------------------------------------------------------------------------\n",
      "Extracted\n",
      "Orpheus: This song is sounding a lot like the blues  genre. Im saying with 73.07 % confidence\n",
      "Confidence Scores\n",
      "blues  : 73.07 %\n",
      "reggae  : 14.6 %\n",
      "hiphop  : 8.85 %\n",
      "Orpheus: Orpheus: Hello! How can I assist you?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orpheus: Hello My Name is DJ ORPHEUS, need some songs im here to help\")\n",
    "amoSim = 0\n",
    "while True:\n",
    "    \n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"extract\":\n",
    "        name = \"music/downloaded/musicaudio.mp3\"\n",
    "        features1 = extract(name)\n",
    "    elif user_input.lower() == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        try:\n",
    "            features1\n",
    "        except NameError:\n",
    "            response = chatbot_response(user_input, amoSim)\n",
    "        else:\n",
    "            response = chatbot_response(user_input,amoSim, features1)\n",
    "        print(f\"Orpheus: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast.n.01 ['fast', 'fasting']\n",
      "fast.v.01 ['fast']\n",
      "fast.v.02 ['fast']\n",
      "fast.a.01 ['fast']\n",
      "fast.a.02 ['fast']\n",
      "fast.a.03 ['fast']\n",
      "fast.s.04 ['fast']\n",
      "fast.s.05 ['fast']\n",
      "debauched.s.01 ['debauched', 'degenerate', 'degraded', 'dissipated', 'dissolute', 'libertine', 'profligate', 'riotous', 'fast']\n",
      "flying.s.02 ['flying', 'quick', 'fast']\n",
      "fast.s.08 ['fast', 'firm', 'immobile']\n",
      "firm.s.10 ['firm', 'loyal', 'truehearted', 'fast']\n",
      "fast.s.10 ['fast']\n",
      "fast.r.01 ['fast']\n",
      "fast.r.02 ['fast', 'tight']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "for ss in wordnet.synsets('fast'):\n",
    "    print(ss.name(), ss.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.turing.com/kb/a-comprehensive-guide-to-named-entity-recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

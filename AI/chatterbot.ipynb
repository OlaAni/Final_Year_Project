{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "%pip install ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Downloading nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nbimporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues' 'classical' 'country' 'disco' 'hiphop' 'jazz' 'metal' 'pop'\n",
      " 'reggae' 'rock']\n",
      "6993 2997 6993 2997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.77      0.83      0.80       302\n",
      "   classical       0.91      0.92      0.92       296\n",
      "     country       0.68      0.76      0.72       312\n",
      "       disco       0.78      0.78      0.78       283\n",
      "      hiphop       0.85      0.79      0.82       320\n",
      "        jazz       0.80      0.81      0.80       289\n",
      "       metal       0.87      0.89      0.88       303\n",
      "         pop       0.84      0.77      0.80       298\n",
      "      reggae       0.78      0.73      0.75       310\n",
      "        rock       0.65      0.61      0.63       284\n",
      "\n",
      "    accuracy                           0.79      2997\n",
      "   macro avg       0.79      0.79      0.79      2997\n",
      "weighted avg       0.79      0.79      0.79      2997\n",
      "\n",
      "Accuracy:  0.7911244577911245\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'..\\data\\Data\\features_3_sec.csv')\n",
    "\n",
    "# df = df.drop(['filename'], axis=1)\n",
    "\n",
    "# df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','label']]\n",
    "\n",
    "df = df[['chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "df['label'] =  label_encoder.fit_transform(df['label'])\n",
    "\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "y = df[['label']]\n",
    "X = df[df.columns.difference(['label'])]\n",
    "\n",
    "\n",
    "## split both X and y using a ratio of 70% training - 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "xgb = xgboost.XGBClassifier(n_estimators=1000,enable_catergorical=True,learning_rate=0.05)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "## make predictions on the test portion (predict the labels of the rows from the test portion of X)\n",
    "predictions = xgb.predict(X_test)\n",
    "\n",
    "target_name = ['blues', 'classical', 'country', 'disco', 'hiphop' ,'jazz' ,'metal', 'pop','reggae' ,'rock']\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_name))\n",
    "## can also output the confusion matrix\n",
    "# cm = confusion_matrix(y_test, predictions)\n",
    "# print(cm)\n",
    "\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "cols_when_model_builds = xgb.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    chroma_sft_mean =  np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    chroma_sft_var =  librosa.feature.chroma_stft(y=y, sr=sr).var()\n",
    "\n",
    "    rms_mean = librosa.feature.rms(y=y).mean()\n",
    "    rms_var = librosa.feature.rms(y=y).var()\n",
    "\n",
    "    spectral_centroid_mean = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "    spectral_centroid_var = librosa.feature.spectral_centroid(y=y, sr=sr).var()\n",
    "\n",
    "    spectral_bandwith_mean = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "    spectral_bandwith_var = librosa.feature.spectral_bandwidth(y=y, sr=sr).var()\n",
    "\n",
    "    rolloff_mean = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "    rolloff_var = librosa.feature.spectral_rolloff(y=y, sr=sr).var()\n",
    "\n",
    "    zero_crossing_rate_mean = librosa.feature.zero_crossing_rate(y=y).mean()\n",
    "    zero_crossing_rate_var = librosa.feature.zero_crossing_rate(y=y).var()\n",
    "\n",
    "\n",
    "    harmony_mean = librosa.effects.harmonic(y).mean()\n",
    "    harmony_var = librosa.effects.harmonic(y).var()\n",
    "\n",
    "    tempo = librosa.feature.tempo(y=y, sr=sr)[0]\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"chroma_sft_mean: \",chroma_sft_mean)\n",
    "    print(\"chroma_sft_var: \",chroma_sft_var)\n",
    "    print(\"rms_mean: \",rms_mean)\n",
    "    print(\"rms_var: \",rms_var)\n",
    "    print(\"spectral_centroid_mean: \",spectral_centroid_mean)\n",
    "    print(\"spectral_centroid_var: \",spectral_centroid_var)\n",
    "    print(\"spectral_bandwith_mean: \",spectral_bandwith_mean)\n",
    "    print(\"spectral_bandwith_var: \",spectral_bandwith_var)\n",
    "    print(\"rolloff_mean: \",rolloff_mean)\n",
    "    print(\"rolloff_var: \",rolloff_var)\n",
    "    print(\"zero_crossing_rate_mean: \",zero_crossing_rate_mean)\n",
    "    print(\"zero_crossing_rate_var: \",zero_crossing_rate_var)\n",
    "    print(\"harmony_mean: \",harmony_mean)\n",
    "    print(\"harmony_var: \",harmony_var)\n",
    "    print(\"tempo: \",tempo)\n",
    "\n",
    "    features = pd.DataFrame({'chroma_stft_mean':[chroma_sft_mean],'chroma_stft_var':[chroma_sft_var],'rms_mean':[rms_mean],'rms_var':[rms_var],'spectral_centroid_mean':[spectral_centroid_mean],\n",
    "                             'spectral_centroid_var':[spectral_centroid_var],'spectral_bandwidth_mean':[spectral_bandwith_mean],'spectral_bandwidth_var':[spectral_bandwith_var],\n",
    "                             'rolloff_mean':[rolloff_mean],'rolloff_var':[rolloff_var],'zero_crossing_rate_mean':[zero_crossing_rate_mean],'zero_crossing_rate_var':[zero_crossing_rate_var],\n",
    "                             'harmony_mean':[harmony_mean],'harmony_var':[harmony_var],'tempo':[tempo],})\n",
    "    \n",
    "\n",
    "    features = features.reindex(columns=cols_when_model_builds)\n",
    "\n",
    "    # features = features.reshape(-1,1)\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def find_sim(data):\n",
    "    placeHoldername = 'test'\n",
    "    data['filename'] = placeHoldername\n",
    "\n",
    "    df_sim = pd.read_csv(r'..\\data\\Data\\features_30_sec.csv')\n",
    "\n",
    "    df_sim = df_sim[['filename','chroma_stft_mean','chroma_stft_var','rms_mean','rms_var','spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var','rolloff_mean','rolloff_var','zero_crossing_rate_mean','zero_crossing_rate_var','harmony_mean','harmony_var','tempo','label']]\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_sim['label'] = df_sim['label'].astype(\"string\")\n",
    "    df_sim['label'] =  label_encoder.fit_transform(df_sim['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    combined_df = pd.concat([df_sim, data], ignore_index=True)\n",
    "\n",
    "    combined_df = combined_df.set_index('filename')\n",
    "\n",
    " \n",
    "    labels = combined_df[['label']]\n",
    "\n",
    "    \n",
    "    scaled = preprocessing.scale(combined_df)\n",
    "    similarity = cosine_similarity(scaled)\n",
    "    sim_df_labels = pd.DataFrame(similarity)\n",
    "    sim_df_names = sim_df_labels.set_index(labels.index)\n",
    "    sim_df_names.columns = labels.index\n",
    "\n",
    "    series = sim_df_names[placeHoldername].sort_values(ascending=False)\n",
    "    series = series.drop(placeHoldername)\n",
    "    return series.head(3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pred(data, features, predicted_feature):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    features = features.drop(['filename'], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, data[predicted_feature], test_size=0.2)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    prediction = model.predict(features)\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "patterns = [\n",
    "    [{\"LOWER\": \"hello\"}],\n",
    "    [{\"LOWER\": \"hi\"}],\n",
    "    [{\"LOWER\": \"how\"}, {\"LOWER\": \"are\"}, {\"LOWER\": \"you\"}],\n",
    "    # [{\"LOWER\": \"find\"}, {\"LOWER\": \"this\"}, {\"LOWER\": \"song\"}, {\"LOWER\": \"but\"}, {\"LOWER\": {\"REGEX\": \".*\"}}],\n",
    "]\n",
    "\n",
    "responses = {\n",
    "    \"greetings\": [\n",
    "        [{\"LOWER\": \"hello\"}],\n",
    "        [{\"LOWER\": \"hi\"}],\n",
    "    ],\n",
    "    \"inquiries\": [\n",
    "        [{\"LOWER\": \"how\"}, {\"LOWER\": \"are\"}, {\"LOWER\": \"you\"}],\n",
    "    ],\n",
    "    \"commands\": [\n",
    "        [{\"LOWER\": \"help\"}],\n",
    "    ],\n",
    "\n",
    "    \"find_increased\": [\n",
    "        [{\"LOWER\": \"find\"}],\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "fast_words = [\"faster\",\"quicker\"]\n",
    "slow_words = [\"slower\",\"calmer\"]\n",
    "\n",
    "\n",
    "for category, patterns in responses.items():\n",
    "    for pattern in patterns:\n",
    "        matcher.add(category, [pattern])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input, features1):\n",
    "   doc = nlp(user_input)\n",
    "   matches = matcher(doc)\n",
    "   if matches:\n",
    "       match_id, start,end = matches[0]\n",
    "       category = nlp.vocab.strings[match_id]\n",
    "       if category == \"greetings\":\n",
    "           return \"Hello! How can I assist you?\"\n",
    "       elif category == \"inquiries\":\n",
    "           return \"I'm just a chatbot. How can I assist you?\"\n",
    "       elif category == \"commands\":\n",
    "           return \"You can ask me for help.\"\n",
    "       \n",
    "       elif category == \"find_increased\":\n",
    "            words = [token.text for token in doc if token.is_alpha]\n",
    "            valid = False\n",
    "            for s in words:\n",
    "                if(s in fast_words):\n",
    "                    features = 'tempo'\n",
    "                    value = 400\n",
    "                    valid=True\n",
    "                elif(s in slow_words):\n",
    "                    features = 'tempo'\n",
    "                    value = -400\n",
    "                    valid=True\n",
    "\n",
    "            if(valid):\n",
    "                new_features = features1\n",
    "                new_features[features] = value\n",
    "                return find_sim(new_features)\n",
    "            else:\n",
    "                return \"I'm sorry, but im going to need a valid song feature\"\n",
    "\n",
    "   else:\n",
    "       return \"I'm sorry, I don't understand that.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orpheus: Hello! How can I assist you?\n",
      "Orpheus: filename\n",
      "hiphop.00015.wav    0.869704\n",
      "rock.00022.wav      0.804720\n",
      "jazz.00077.wav      0.799673\n",
      "Name: test, dtype: float64\n",
      "Orpheus: filename\n",
      "metal.00066.wav    0.659675\n",
      "metal.00045.wav    0.659675\n",
      "rock.00023.wav     0.601153\n",
      "Name: test, dtype: float64\n",
      "Orpheus: filename\n",
      "metal.00066.wav    0.659675\n",
      "metal.00045.wav    0.659675\n",
      "rock.00023.wav     0.601153\n",
      "Name: test, dtype: float64\n",
      "Orpheus: filename\n",
      "metal.00066.wav    0.659675\n",
      "metal.00045.wav    0.659675\n",
      "rock.00023.wav     0.601153\n",
      "Name: test, dtype: float64\n",
      "Orpheus: I'm sorry, but im going to need a valid song feature\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"extract\":\n",
    "        print(\"Loading....\")  \n",
    "        features1 = extract_features(r\"..\\music\\Beyoncé-Single Ladies.mp3\")\n",
    "        print(\"Extracted\")\n",
    "        genre1 = xgb.predict(features1)\n",
    "        print(genre1)\n",
    "        features1['label'] = genre1[0]\n",
    "\n",
    "    elif user_input.lower() == \"sim\":\n",
    "        print(\"Similiar Songs:\",find_sim(features1))\n",
    "    elif user_input.lower() == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        response = chatbot_response(user_input,features1)\n",
    "        print(f\"Orpheus: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
